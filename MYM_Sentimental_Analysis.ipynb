{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kG9SDMTfPde"
      },
      "outputs": [],
      "source": [
        "# install libraries \n",
        "\n",
        "!pip install pandas matplotlib tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGLTRKbIfjTW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"./Tweets.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_EVVe3Wf5sd"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8nIdDRcXv2i"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfH7quiEX4cD"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVeoQ2srX8JG"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rZkOUZvf65p"
      },
      "outputs": [],
      "source": [
        "# need only the sentimental and text columns\n",
        "\n",
        "review_df = df[['text','airline_sentiment']]\n",
        "\n",
        "print(review_df.shape)\n",
        "review_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG5oBGdqgSzk"
      },
      "source": [
        "EDA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEjH4SzvgPE6"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVLExfuwgVkz"
      },
      "outputs": [],
      "source": [
        "# Drop the neutral reviews because this is the binary classification so we need only positive and negative\n",
        "review_df = review_df[review_df['airline_sentiment'] != 'neutral']\n",
        "\n",
        "print(review_df.shape)\n",
        "review_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoqVcQ3hgauW"
      },
      "outputs": [],
      "source": [
        "review_df[\"airline_sentiment\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IVzHu3Md2oH"
      },
      "source": [
        "Text preprocessing (tokenization, padding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt0YZfbPg24P"
      },
      "outputs": [],
      "source": [
        "# convert categorical values into numerical values\n",
        "\n",
        "# positive = 0 and negative = 1\n",
        "sentiment_label = review_df.airline_sentiment.factorize()\n",
        "sentiment_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4bhnjmBWX4M"
      },
      "outputs": [],
      "source": [
        "tweet = review_df.text.values\n",
        "tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOVnkdCnYT7X"
      },
      "outputs": [],
      "source": [
        "# tokenize all the text\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "\n",
        "tokenizer.fit_on_texts(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saD7FtEpYej1"
      },
      "outputs": [],
      "source": [
        "# replace the words with their assigned numbers\n",
        "encoded_docs = tokenizer.texts_to_sequences(tweet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHiFV0-GYzLr"
      },
      "outputs": [],
      "source": [
        "# padding to pad the sentences to have equal length\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded_sequence = pad_sequences(encoded_docs, maxlen=200)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWMm4suEY-Kv"
      },
      "source": [
        "Text Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ofw-7HOZTkg"
      },
      "source": [
        "Here I use LSTM architecture for this task , because it's work well with text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xcIcnH2Y5rA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential , load_model\n",
        "from tensorflow.keras.layers import LSTM,Dense, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_vector_length, input_length=200))\n",
        "model.add(SpatialDropout1D(0.25))\n",
        "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du59BG9lba-J"
      },
      "source": [
        "Train model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOvu_oxDZ1o5"
      },
      "outputs": [],
      "source": [
        "history = model.fit(padded_sequence,sentiment_label[0],validation_split=0.2, epochs=5, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbmJLLsux9pU"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "model.save(\"./sentimental_analysis.h5\")\n",
        "\n",
        "# It can be used to reconstruct the model identically.\n",
        "inference_model = load_model(\"./sentimental_analysis.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hnO7Lw4b_jX"
      },
      "source": [
        "Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjKdDpVOaee4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZvm4ZLdcFuE"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKQ0gC2vcLsb"
      },
      "source": [
        "Inference the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxiOc_4ZcKNi"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text):\n",
        "    tw = tokenizer.texts_to_sequences([text])\n",
        "    tw = pad_sequences(tw,maxlen=200)\n",
        "    prediction = int(model.predict(tw).round().item())\n",
        "    print(\"Predicted label: \", sentiment_label[1][prediction])\n",
        "\n",
        "\n",
        "test_sentence1 = \"I enjoyed my journey on my first flight.\"\n",
        "predict_sentiment(test_sentence1)\n",
        "\n",
        "test_sentence2 = \"This is the worst flight experience of my life!\"\n",
        "predict_sentiment(test_sentence2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAyvon7ScVXS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
